# LangGraph Minimal - Responses API + LangGraph Architecture

A production-ready, minimal setup combining OpenAI's Responses API with LangGraph workflows for maximum flexibility and power.

## ğŸš€ **Architecture Overview**

This project implements a **modern hybrid architecture** that leverages the best of both worlds:

1. **Tools** (`packages/tools`) - Framework-agnostic plain TypeScript functions
2. **Graphs** (`packages/graphs`) - LangGraph workflows that orchestrate tools with AI enhancement
3. **Agent API** (`packages/agent`) - OpenAI Responses API with built-in tools + custom workflows
4. **Gateway** (`gateways/langserve`) - Fastify server exposing both Agent API and direct workflow access

## âœ¨ **Key Features**

- **ğŸ”„ OpenAI Responses API**: Latest unified API with built-in tools (web search, code interpreter)
- **ğŸ§  LangGraph Integration**: Full state management and workflow orchestration
- **ğŸ› ï¸ Built-in Tools**: Real-time web search, code execution with container management
- **ğŸ¯ Custom Tools**: Framework-agnostic TypeScript functions
- **ğŸ“Š Observability**: Built-in tracing, logging, and performance monitoring
- **âš¡ TypeScript**: Full type safety across the entire project
- **ğŸ›ï¸ Feature Flags**: Runtime control over built-in tools
- **ğŸš€ Production Ready**: Error handling, container lifecycle management

## ğŸ› ï¸ **Available Tools**

### **Built-in OpenAI Tools (Responses API)**
- **`web_search_preview`** - Real-time web search with current information
- **`code_interpreter`** - Code execution with automatic container management

### **Custom Tools**
- **`get_weather`** - Weather information for any location
- **`calculate`** - Mathematical calculations with precision control

### **LangGraph Workflows**
- **`weather_workflow`** - Weather data + AI-powered recommendations
- **`search_workflow`** - Web search + AI summarization

## ğŸš€ **Quickstart**

```bash
# Install dependencies
corepack enable
npm i -g pnpm@9
pnpm install

# Set up environment variables
cp .env.example .env
# Edit .env and add your API keys:
# - OPENAI_API_KEY (required)

# Start development
pnpm dev

# Test the API
curl -X POST http://localhost:3000/agent \
  -H "Content-Type: application/json" \
  -d '{"message": "What is 15 * 23?"}'
```

## ğŸ“ **Project Structure**

```
langgraph-minimal/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ tools/          # Framework-agnostic tools (plain TS functions)
â”‚   â”œâ”€â”€ graphs/         # LangGraph workflows with AI enhancement
â”‚   â”œâ”€â”€ agent/          # Responses API layer with built-in tools
â”‚   â””â”€â”€ core/           # Shared utilities and configurations
â”œâ”€â”€ gateways/
â”‚   â””â”€â”€ langserve/      # Fastify server for serving agent and workflows
â”œâ”€â”€ package.json        # Root workspace configuration
â””â”€â”€ README.md          # This file
```

## ğŸ”Œ **API Endpoints**

### **Agent API**
```bash
# Main agent endpoint
POST /agent
Content-Type: application/json

{
  "message": "What's the weather like in San Francisco?"
}
```

### **Feature Flag Management**
```bash
# Enable built-in tools
POST /api/enable-builtin-tools

# Disable built-in tools
POST /api/disable-builtin-tools

# Toggle built-in tools
POST /api/toggle-builtin-tools

# Check current flags
GET /api/flags
```

### **Health Check**
```bash
GET /ping
```

## ğŸ§ª **Usage Examples**

### **Basic Calculations**
```bash
curl -X POST http://localhost:3000/agent \
  -H "Content-Type: application/json" \
  -d '{"message": "What is 15 * 23?"}'
```

### **Real-time Web Search**
```bash
curl -X POST http://localhost:3000/agent \
  -H "Content-Type: application/json" \
  -d '{"message": "What is the current weather in San Francisco?"}'
```

### **LangGraph Workflow**
```bash
curl -X POST http://localhost:3000/agent \
  -H "Content-Type: application/json" \
  -d '{"message": "Get weather information for Tokyo using the weather_workflow"}'
```

### **Code Execution**
```bash
curl -X POST http://localhost:3000/agent \
  -H "Content-Type: application/json" \
  -d '{"message": "Calculate the factorial of 10"}'
```

## ğŸ”§ **How It Works**

### **1. Tools Layer**
Tools are plain TypeScript functions with Zod validation:

```typescript
// packages/tools/src/weather.ts
export const weatherTool: Tool = {
  name: "get_weather",
  description: "Get weather information",
  parameters: WeatherParams,
  execute: async (args) => {
    // Implementation here
  }
};
```

### **2. Graphs Layer**
Workflows orchestrate tools with AI enhancement:

```typescript
// packages/graphs/src/weather-workflow.ts
export const runWeatherWorkflow = async (location: string) => {
  const weatherData = await weatherTool.execute({ location });
  const recommendations = await generateAIRecommendations(weatherData);
  return { weatherData, recommendations };
};
```

### **3. Agent Layer (Responses API)**
The Agent API uses OpenAI's Responses API with built-in tools:

```typescript
// packages/agent/src/index.ts
const response = await responsesClient.ask({
  input: message,
  tools: [
    { type: "web_search_preview" },
    { type: "code_interpreter", container: containerId },
    // Custom tools and workflows
  ]
});
```

### **4. Gateway Layer**
Exposes both Agent API and direct workflow access:

```typescript
// Agent API (Responses API)
fastify.post("/agent", async (request, reply) => {
  const response = await agentAPI.runAgent(message);
  return { response };
});
```

## ğŸ—ï¸ **Technical Architecture**

### **Responses API Integration**
- **Built-in Tools**: `web_search_preview`, `code_interpreter`
- **Container Management**: Automatic creation and reuse
- **Schema Compatibility**: Proper JSON schema validation
- **Error Handling**: Robust error recovery

### **LangGraph State Management**
- **Tracing**: Full request tracing with unique IDs
- **Performance**: Timing and performance monitoring
- **Logging**: Comprehensive event logging
- **Error Recovery**: Graceful error handling

### **Feature Flag System**
- **Runtime Control**: Enable/disable built-in tools
- **A/B Testing**: Toggle capabilities for testing
- **Configuration**: JSON-based flag management

## ğŸ“Š **Performance & Benefits**

### **Responses API Advantages**
- âœ… **Built-in Tools**: Real-time web search, code interpreter
- âœ… **Stateful**: Maintains conversation context
- âœ… **Unified**: Single API for all tool types
- âœ… **Simpler**: No complex tool call handling

### **LangGraph Benefits**
- âœ… **Observability**: Full tracing and monitoring
- âœ… **State Management**: Proper workflow state tracking
- âœ… **Performance**: Optimized execution with timing
- âœ… **Error Handling**: Robust error recovery

## ğŸ”„ **Migration from Chat Completions**

This project has fully migrated from OpenAI's Chat Completions API to the Responses API:

### **What Changed**
- âœ… **Removed**: Chat Completions API entirely
- âœ… **Added**: Responses API with built-in tools
- âœ… **Enhanced**: Container management for code interpreter
- âœ… **Simplified**: Single API architecture

### **Benefits Achieved**
- ğŸš€ **Better Performance**: Built-in tools are faster
- ğŸ”§ **Simpler Code**: No dual API complexity
- ğŸ¯ **More Capabilities**: Real-time search, code execution
- ğŸ“Š **Better Observability**: Unified tracing

## ğŸš€ **Production Deployment**

### **Environment Variables**
```bash
OPENAI_API_KEY=your_openai_api_key
```

### **Build & Deploy**
```bash
# Build all packages
pnpm build

# Start production server
pnpm start
```

### **Docker Support**
```bash
# Build Docker image
docker build -t langgraph-minimal .

# Run container
docker run -p 3000:3000 -e OPENAI_API_KEY=your_key langgraph-minimal
```

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ **License**

MIT License - see LICENSE file for details.

## ğŸ†˜ **Support**

- **Issues**: Create an issue on GitHub
- **Discussions**: Use GitHub Discussions
- **Documentation**: Check the code comments and examples

---

**Built with â¤ï¸ using OpenAI Responses API + LangGraph**
